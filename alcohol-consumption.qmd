---
title: "Student Alcohol Consumption"
title-block-banner: true
author: "Pascal Hasenkamp"
theme: minty
listing: default
format: 
  html: 
    toc: true
    toc-title: "Inhalt und Struktur"
    toc_float: true
    embed-resources: true
    code-fold: true
    code-summary: "Code anzeigen"
date: 2024-09-18
editor: 
  markdown: 
    wrap: sentence
---

```{r = packets, include=FALSE}
library(tidyverse)
library(tidymodels)
library(tidyverse) 
library(tidymodels)
library(explore) 
library(rpart.plot)
library(corrplot)
library(GGally)
library(tidyr)
library(dplyr)
library(ggplot2)
library(parsnip)
library(yardstick)
library(caret)
library(ranger)
```

# Aufgabe und Daten verstehen

In dieser Arbeit sollen verschiedenste Zusammenhänge zwischen Lebensumständen bei Studenten zweier Kurse (Mathe, im Datensatz math und Portugiesisch, im Datensatz portuguese) einer "Secondary School", vergleichbar mit einer deutschen weiterführenden Schule, untersucht und beschrieben werden.

Hierzu stehen die Datensätze der Studenten bzw.
der Kurse bei Kaggle unter <https://www.kaggle.com/datasets/uciml/student-alcohol-consumption/data> zur Verfügung.

## Daten einlesen und zusammenführen

Als Start lesen wird beide Datensätze ein, aufgrund von Formatierungs und MergeProblemen wird noch das Encoding in "UTF-8" gesetzt.

```{r, message=FALSE}
d_mat <- read.csv("dataset/student-mat.csv", header = TRUE, fileEncoding = "UTF-8")
d_por <- read.csv("dataset/student-por.csv", header = TRUE, fileEncoding = "UTF-8")
```

Anschließend prüfen wir, dass alle gemeinsamen Spalten korrekt angegeben und in beiden Datensätzen vorhanden sind.
Die ausgewählten Spalten sind in der Datei "student-merge.R" des heruntergeladenen Archivs angegeben.

```{r, message=FALSE}
# Anzeigen der Spaltennamen in Datensatz Mathe
print(colnames(d_mat))
# Anzeigen der Spaltennamen in Datensatz Portugiesisch
print(colnames(d_por))

common_columns <- c("school", "sex", "age", "address", "famsize", "Pstatus", 
                    "Medu", "Fedu", "Mjob", "Fjob", "reason", "nursery", "internet")

# Vorhanden in beiden Datensätzen?
if (!all(common_columns %in% colnames(d_mat)) | !all(common_columns %in% colnames(d_por))) {
  stop("Nicht alle angegebenen Spalten sind in beiden Datensätzen vorhanden.")
}
```

Danach werden die beiden Datensätze in "untidy_student_data" zusammengeführt:

```{r, message=FALSE}
untidy_student_data <- merge(d_mat, d_por, by = common_columns)
```

## Aufbereitung und "tidy"

Der kombinierte Datensatz ist aktuell nicht als *tidy* zu betrachten.
Es wurde sich dafür entschieden einen kombinierten und aufgeräumten Datensatz zu erstellen, um beide Kurse gleichzeitig in der explorativen Datenanalyse zu betrachten und eine Einheitlichkeit bei der Datenstruktur zu behalten.
Die Übersichtlichkeit ist durch keine Dopplung einiger Attribute, wie es in einem Beispiel mit 2 Kursen und einem nicht gemergten Datensatz bzw.
einem Datensatz mit mehreren Kursen der Kursteilnehmer vorgelegen hätte, gegeben.

In dem Datensatz "untidy_student_data" wäre ein Datensatz mit 53 Spalten, hier haben die Studenten in den zusätzlichen Spalten, welche in 2 Kursen eingeschrieben sind.
Dieser Datensatz wird allerdings nicht weiterverwendet.

Das Kombinieren aus dem "untidy_student_data" Datensatz in einen "student_data" geschiet mit folgendem Code:

```{r, message=FALSE}
student_data <- untidy_student_data %>%
  pivot_longer(
    cols = ends_with(c(".x", ".y")), 
    names_to = c(".value", "course"),
    names_sep = "\\."
  ) %>%
  
  mutate(course = ifelse(course == "x", "Mathematik", "Portugiesisch"))
```

Die Daten sind nun in einem Datensatz, dem "student_data" zusammengefasst und haben die Spalte "course" erhalten.
Der Einfachheit halber werden die Datensätze ab jetzt als ein Datensatz behandelt.

Wir müssen uns nicht um das aufräumen von fehlenden Angaben kümmern, da es keine Beobachtungen mit fehlenden Einträgen gibt:

```{r, message=FALSE}
describe_tbl(student_data)
```

Zur Sicherung wird der kombinierte Datensatz noch als .csv exportiert:

```{r, message=FALSE}
# Auskommentiert um Datei NICHT zu erzeugen
#write.csv(student_data, file = "dataset/student_data.csv", row.names = FALSE)
```

## Thesen aufstellen

Folgende Thesen sollen explorativ untersucht werden und kommen gegebenenfalls in der Modellfindung zum Einsatz.
Sollten Probleme mit Thesen auftreten oder sich neue Informationen aus diesen ergeben, wird dies in einem späteren Teil des Dokumentes behandelt.
Aufgrund des Datensatzes wurden 9 Thesen aufgestellt, im Vorhinein wurde sich mit der Dozentin auf die Aufstellung einer höheren Anzahl an Thesen geeinigt.

**These 1: Studenten, die in der Stadt leben, erzielen bessere Noten als Studenten auf dem Land.**

**These 2: Studenten, deren Eltern eine höhere Bildung haben, erzielen bessere Noten.**

**These 3: Studenten, die in einer intakten Familie leben, haben eine höhere durchschnittliche Abschlussnote.**

**These 4: Es gibt einen Zusammenhang zwischen der Anzahl der vergangenen Fehlversuche und der Abschlussnote.**

**These 5: Studenten, die regelmäßig Alkohol konsumieren, haben schlechtere Noten.**

**These 6: Das Geschlecht hat einen Einfluss auf die Schulleistung.**

**These 7: Studenten mit Zugang zum Internet zu Hause schneiden im Durchschnitt besser ab.**

**These 8: Studenten, mit einer höhere Abwesenheitsrate neigen dazu, schlechtere Noten zu haben.**

**These 9: Es gibt einen Zusammenhang zwischen der Nutzung von Nachhilfe und den Abschlussnoten.**

Es wurden aufgrund des Umfanges der Analyse nicht alle Thesen mit Methoden der EDA untersucht.
Die Nummerierung wie sie hier zu finden ist, wird auch im Rest des Dokumentes für die Übersichtlichkeit verwendet.

## Überblick

Wir schauen uns die Daten zunächst einmal an:

```{r}
knitr::kable(head(student_data), caption = "Das Spaltenformat des eingelesenen Studentendatensatzes")
```

Der Datensatz hat **`r nrow(student_data)`** Zeilen und **`r ncol(student_data)`** Spalten.
Die Daten sind wie im vorherigen Teil der Dokumentation beschrieben *tidy*, das bedeutet:

1.  Jede Variable hat ihre eigene Spalte
2.  Jede Beobachtung hat ihre eigene Zeile
3.  Jeder Wert hat seine eigene Zelle

Die Variablen haben folgende Bedeutungen:

| Variable       | Typ  | Bedeutung                                                                                                            |
|:-------------------|:-------------------|:-------------------------------|
| **school**     | char | Schule des Studenten ('GP' - Gabriel Pereira oder 'MS' - Mousinho da Silveira)                                       |
| **sex**        | char | Geschlecht des Studenten ('F' - weiblich, 'M' - männlich)                                                            |
| **age**        | int  | Alter des Studenten (von 15 bis 22)                                                                                  |
| **address**    | char | Wohnort des Studenten ('U' - städtisch, 'R' - ländlich)                                                              |
| **famsize**    | char | Familiengröße ('LE3' - kleiner oder gleich 3, 'GT3' - größer als 3)                                                  |
| **Pstatus**    | char | Zusammenleben der Eltern ('T' - zusammen, 'A' - getrennt)                                                            |
| **Medu**       | int  | Bildungsniveau der Mutter (0 - keine, 1 - Grundschule, 2 - 5. bis 9. Klasse, 3 - Sekundarschule, 4 - höhere Bildung) |
| **Fedu**       | int  | Bildungsniveau des Vaters (0 - keine, 1 - Grundschule, 2 - 5. bis 9. Klasse, 3 - Sekundarschule, 4 - höhere Bildung) |
| **Mjob**       | char | Beruf der Mutter ('teacher', 'health', 'services', 'at_home', 'other')                                               |
| **Fjob**       | char | Beruf des Vaters ('teacher', 'health', 'services', 'at_home', 'other')                                               |
| **reason**     | char | Grund für die Wahl der Schule ('home', 'reputation', 'course', 'other')                                              |
| **guardian**   | char | Erziehungsberechtigter ('mother', 'father', 'other')                                                                 |
| **traveltime** | int  | Fahrzeit zur Schule (1 - \<15 Min., 2 - 15 bis 30 Min., 3 - 30 Min. bis 1 Std., 4 - \>1 Std.)                        |
| **studytime**  | int  | Wöchentliche Lernzeit (1 - \<2 Std., 2 - 2 bis 5 Std., 3 - 5 bis 10 Std., 4 - \>10 Std.)                             |
| **failures**   | int  | Anzahl der bisherigen Fehler (n, wenn 1 \<= n \< 3, sonst 4)                                                         |
| **schoolsup**  | char | Zusätzliche Bildungsunterstützung ('yes', 'no')                                                                      |
| **famsup**     | char | Familienunterstützung ('yes', 'no')                                                                                  |
| **paid**       | char | Zusätzliche bezahlte Klassen (Mathematik oder Portugiesisch) ('yes', 'no')                                           |
| **activities** | char | Teilnahme an außerschulischen Aktivitäten ('yes', 'no')                                                              |
| **nursery**    | char | Besuch des Kindergartens ('yes', 'no')                                                                               |
| **higher**     | char | Wunsch nach höherer Bildung ('yes', 'no')                                                                            |
| **internet**   | char | Internetzugang zu Hause ('yes', 'no')                                                                                |
| **romantic**   | char | In einer romantischen Beziehung ('yes', 'no')                                                                        |
| **famrel**     | int  | Qualität der familiären Beziehungen (1 - sehr schlecht bis 5 - exzellent)                                            |
| **freetime**   | int  | Freizeit nach der Schule (1 - sehr wenig bis 5 - sehr viel)                                                          |
| **goout**      | int  | Zeit mit Freunden verbringen (1 - sehr wenig bis 5 - sehr viel)                                                      |
| **Dalc**       | int  | Alkoholkonsum unter der Woche (1 - sehr wenig bis 5 - sehr viel)                                                     |
| **Walc**       | int  | Alkoholkonsum am Wochenende (1 - sehr wenig bis 5 - sehr viel)                                                       |
| **health**     | int  | Aktueller Gesundheitszustand (1 - sehr schlecht bis 5 - sehr gut)                                                    |
| **absences**   | int  | Anzahl der Abwesenheiten (0 bis 93)                                                                                  |
| **G1**         | int  | Note für die erste Periode (0 bis 20)                                                                                |
| **G2**         | int  | Note für die zweite Periode (0 bis 20)                                                                               |
| **G3**         | int  | Abschlussnote (0 bis 20, Zielvariable)                                                                               |

Zunächst verschaffen wir uns einen Überblick über die Daten.

```{r}
glimpse(student_data)
```

```{r}
summary(student_data)
```

## Ausreißerprüfung

Zuerst prüfen wir auf Ausreißer in den numerischen Variablen mit Hilfe von Boxplots

### Numerische Variablen identifizieren

```{r}
numeric_vars <- student_data %>% select(where(is.numeric))
```

### Boxplots für alle numerischen Variablen erstellen

```{r}
numeric_vars %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Wert") %>%
  ggplot(aes(x = Variable, y = Wert)) +
  geom_boxplot() +
  coord_flip() +  # bessere Lesbarkeit durch links/rechts Darstellung
  theme_minimal() +
  labs(title = "Boxplots zur Identifizierung von Ausreißern in numerischen Variablen")
```

Beschreibende Statistik für die numerischen Variablen, um einen Überblick zu bekommen

```{r}
summary(numeric_vars)
```

### Bereinigen der Ausreißer

Wir verwenden eine Funktion zur Erkennung und Entfernung von Ausreißern mit der IQR-Methode:

```{r}
remove_outliers <- function(data) {
  numeric_vars <- data %>% select(where(is.numeric))
  
  for (var in names(numeric_vars)) {
    Q1 <- quantile(numeric_vars[[var]], 0.25, na.rm = TRUE)
    Q3 <- quantile(numeric_vars[[var]], 0.75, na.rm = TRUE)
    IQR <- Q3 - Q1
    
    # Berechnung der oberen und unteren Grenzen für die Ausreißer
    lower_bound <- Q1 - 1.5 * IQR
    upper_bound <- Q3 + 1.5 * IQR
    
    # Filtern der Zeilen, die innerhalb der Grenzen liegen
    data <- data %>% filter((!!sym(var) >= lower_bound) & (!!sym(var) <= upper_bound))
  }
  
  return(data)
}
```

Entfernen der Ausreißer aus dem Datensatz bzw.
schreiben in einen neuen "student_data_cleaned" Datensatz:

```{r}
student_data_cleaned <- remove_outliers(student_data)
```

Und ein Überblick über den bereinigten Datensatz:

```{r}
summary(student_data_cleaned)
```

# Explorative Datenanalyse

Wir beginnen zuerst mit einem ersten Überblick über die Zusammenhänge und der Verteilung.
Hierfür schauen wir uns die Daten von These 1., These 2.
und These 7.
an.
Diese Thesen wurden aufgrund des möglichen Zusammenhanges mit der Abschlussnote ausgewählt, ohne direkt die negativen Aspekte des Alkoholkonsumes zu bewerten.

## Verteilung der Noten G1, G2 und G3

```{r}

ggplot(student_data_cleaned, aes(x = G1)) +
  geom_histogram(binwidth = 1, fill = "skyblue", color = "black") +
  labs(title = "Verteilung der Noten in der ersten Periode (G1)", x = "Note", y = "Häufigkeit")

ggplot(student_data_cleaned, aes(x = G2)) +
  geom_histogram(binwidth = 1, fill = "skyblue", color = "black") +
  labs(title = "Verteilung der Noten in der zweiten Periode (G2)", x = "Note", y = "Häufigkeit")

ggplot(student_data_cleaned, aes(x = G3)) +
  geom_histogram(binwidth = 1, fill = "skyblue", color = "black") +
  labs(title = "Verteilung der Abschlussnoten (G3)", x = "Note", y = "Häufigkeit")
```

Es ist erkennbar, dass die Notenverteilung über alle Perioden generell der Form der Standardabweichung ähnelt, die meisten Noten also im Mittelfeld angesiedelt sind.

## Einfluss der Thesen 1., 2. und 7. auf die Abschlussnote G3

### Wohnort x Abschlussnote

```{r}
ggplot(student_data_cleaned, aes(x = address, y = G3, fill = address)) +
  geom_boxplot() +
  labs(title = "Einfluss des Wohnorts auf die Abschlussnote", x = "Wohnort (U = städtisch, R = ländlich)", y = "Abschlussnote (G3)")
```

Im ersten Boxblot lässt sich die Verteilung so erkennen, dass Studenten aus städtischen Gebieten eher eine bessere Note (=höhere Punktzahl) aufweisen, als Studenten aus ländlichen Gebieten.

These 1 kann somit als **"bestätig"** behandelt werden.

### Bildungsniveau Mutter x Abschlussnote

```{r}
ggplot(student_data_cleaned, aes(x = factor(Medu), y = G3, fill = factor(Medu))) +
  geom_boxplot() +
  labs(title = "Einfluss des Bildungsniveaus der Mutter auf die Abschlussnote", x = "Bildungsniveau der Mutter", y = "Abschlussnote (G3)")
```

In dieser Betrachtung ist erkennbar, dass der Trend in den Bildungskategorien 1-4 (Bildung ist vorhanden) zu einem steigenden Trend geht, je höher die Bildung der Mutter ist.
Lediglich bei keiner Bildung (=Bildungskategorie 0) reißt diese Verteilung aus und überzeugt mit einer hohen Punktzahl bei der Abschlussnote.

Die Informationen werden bei "Vater x Abschlussnote" weiter behandelt.

### Bildungsniveau Vater x Abschlussnote

```{r}
ggplot(student_data_cleaned, aes(x = factor(Fedu), y = G3, fill = factor(Fedu))) +
  geom_boxplot() +
  labs(title = "Einfluss des Bildungsniveaus des Vaters auf die Abschlussnote", x = "Bildungsniveau des Vaters", y = "Abschlussnote (G3)")
```

Die Verteilung lässt sich ähnlich Beschreiben wie bei "Bildungsniveau Mutter x Abschlussnote".
In Bildungskategorie 3 ist nur ein kleiner Abfall der Abschlussnote erkennbar.
Bei fehlender Bildung des Vaters gibt es weiterhin einer überdurchschnittlich hohe erreichte Punktzahl in der Abschlussnote.

Generell kann jedoch These 2 als **"bestätigt"** behandelt werden.
Da es schwierig ist eine Aussage über die nicht-gebildeten Elternteile zu treffen, wird dies vorerst aus der Betrachtung ausgeklammert.

### Internet Zuhause x Abschlussnote

```{r}
ggplot(student_data_cleaned, aes(x = internet, y = G3, fill = internet)) +
  geom_boxplot() +
  labs(title = "Einfluss von Internetzugang auf die Abschlussnote", x = "Internet zu Hause (Ja/Nein)", y = "Abschlussnote (G3)")
```

Kurz lässt sich hier erkennen, dass Studenten mit Internet zu Hause durchschnittlich eine bessere Abschlussnote erreichen, als Studenten ohne Internet zu Hause.
Dies lässt These 7 als **"bestätigt"** abhaken.

## Streudiagramm für These 8.

Durch den Bezug zur Abschlussnote G3 wird auch die Anzahl der Abwesenheiten betrachtet, diesmal in einem Streudiagramm:

```{r}

ggplot(student_data_cleaned, aes(x = absences, y = G3)) +
  geom_point(alpha = 0.6, color = "darkgrey", size = 2) +
  geom_smooth(formula = y ~ x,method = "lm", se = TRUE, color = "red", linetype = "dashed") + 
  labs(title = "Zusammenhang zwischen Abwesenheiten und Abschlussnote",
       x = "Anzahl der Abwesenheiten (absences)",
       y = "Abschlussnote (G3)") +
  theme_minimal()
```

Es lässt sich in der roten Regressionslinie (geom_smooth) ein Abwärtstrend erkennen, sprich, mit steigender Zahl der Abwesenheiten sinken die Leistungen und die Abschlussnoten werden schlechter.

## Korrelationsmatrix

Eine Variable in dem Datensatz hat eine Standardabweichung von 0:

```{r}
sd_check <- sapply(student_data_cleaned %>% select(where(is.numeric)), sd, na.rm = TRUE)
constant_vars <- names(sd_check[sd_check == 0])
print(constant_vars)
```

Es ist "failures", diese ist allerdings relevant, soll jedoch nicht mit in die Berechnung einbezogen werden, da sie konstant ist.

**Korrelationsmatrix der numerischen Variablen ohne 'failures'**

```{r}
student_data_cleaned_non_constant <- student_data_cleaned %>% select(-failures)
cor_matrix <- cor(student_data_cleaned_non_constant %>% select(where(is.numeric)), use = "complete.obs")
corrplot(cor_matrix, method = "color", type = "upper", tl.cex = 0.7)
```

Diese Interpretationsmatrix hat die Variablen zueinander dargestellt, hierbei fällt folgendes auf:

### Starke positive Korrelation

Im Unteren Bereich ist zu erkennen, dass die Noten G1 und G2, sowie die Abschlussnote G3 eine starke positive Korrelation aufweisen.
Eine konsistente Leistung in der Periode G1 und G2 spiegelt sich also in der Abschlussnote wieder.

Ebenfalls lässt sich zwischen der Bildung der Elternteile eine positive Korrelation feststellen.
Eltern, bzw.
Partner suchen sich oft gegenseitig mit ähnlichen Bildungsstufen aus.

Der Alkoholkonsum in der Woche (Dalc) sowie am Wochenende (Walc) korrelieren ebenfalls stark positiv miteinander, was darauf hinweist, dass Studenten, die unter der Woche viel Alkohol trinken, dies auch am Wochenende tun.
--\> Hier kann direkt auf These 5 eingegangen werden, da keine klare Korrelation der Variablen Alkoholkonsum (Dalc/Walc) und der Abschlussnote (G3) erkennbar ist.
Angenommen werden kann also, dass in dem Datensatz kein starker Einfluss besteht oder andere Faktoren wichtiger für die Abschlussnote sind.

### Starke negative Korrelation

Es gibt keine starken negativen Korrelationen in der Matrix.
Die negativen (jedoch schwachen) Korrelationen werden in dem nächsten Abschnitt behandelt.

### Mittlere oder schwache Korrelation

Auch hier kann ein Fokus auf die Abschlussnote gelegt werden.
Die Lernzeit (studytime) hat eine schwache positive Korrelation mit der Abschlussnote (G3), dies zeigt, dass eine höhere Lernzeit nur einen bedingten Einfluss auf eine bessere Abschlussnote hat.

Die Abwesenheit (absence) hat eine leichte negative korrelation mit der Abschlussnote (G3), also ist eine häufige Abwesenheit mit schlechteren Noten verbunden, nur nicht mit einem starken Zusammenhang.

Hervorzuheben ist ebenfalls noch der Zusammenhang zwischen dem Alkholkonsum am Wochenende (Walc) und der Familienbeziehung (famrel).
In intakten Familien wird am Wochenede also eher weniger Alkohol konsumiert.

Die schwache negative Korrelation zwischen Lernzeit (studytime) und Alkoholkonsum am Wochenende (Walc) zeigt, dass Studenten, die mehr Zeit mit Lernen verbringen, tendenziell weniger Alkohol trinken.

### Auswertung

Die Analyse und Interpretation der Korrelationsmatrix der numerischen Variablen kann Aussagen zu zwei Thesen treffen:

-   These 5: Diese kann als **"nicht bestätigt"** behandelt werden. Die Korrelationsmatrix zeigt keine klare Korrelation zwischen Alkoholkonsum (`Dalc`, `Walc`) und der Abschlussnote (`G3`), was darauf hinweist, dass in diesem Datensatz und dieser Beobachtung kein starker Einfluss des Alkoholkonsums auf die Noten besteht.
-   These 8: Diese kann **"bestätigt"** werden. Die Korrelationsmatrix zeigt eine leichte negative Korrelation zwischen der Anzahl der Abwesenheiten (`absences`) und der Abschlussnote (`G3`), was darauf hinweist, dass Schüler mit mehr Abwesenheiten tendenziell schlechtere Noten haben.

## Thesenübersicht

Hier ist der aktuelle Stand zu den 9 Thesen, welche untersucht werden sollen:

| These   | Status          |
|---------|-----------------|
| These 1 | bestätigt       |
| These 2 | bestätigt\*     |
| These 3 | steht aus       |
| These 4 | steht aus       |
| These 5 | nicht bestätigt |
| These 6 | steht aus       |
| These 7 | bestätigt       |
| These 8 | bestätigt       |
| These 9 | steht aus       |

\* diese These wird mit der Exkludierung der nicht-gebildeten Elternteile bestätigt

## Untersuchung der Restthesen

Um ein Ergebnis zu erhalten schauen wir uns jetzt spezifisch die Thesen 3, 4, 6, und 9 an, da diese noch keinen Status haben.

------------------------------------------------------------------------

**These 3**

"Studenten, die in einer intakten Familie leben, haben eine höhere durchschnittliche Abschlussnote."

```{r}
avg_grade_by_family <- aggregate(G3 ~ Pstatus, data = student_data, FUN = mean)
print(avg_grade_by_family)
```

```{r}
ggplot(student_data_cleaned, aes(x = Pstatus, y = G3, fill = Pstatus)) +
  geom_boxplot() +
  labs(title = "Einfluss des Familienstatus auf die Abschlussnote",
       x = "Familienstatus (T = zusammen, A = getrennt)",
       y = "Abschlussnote (G3)")

```

In beiden Darstellungen wird ersichtlich, dass Studenten, die in einer nicht-intakten Familie leben (Pstatus "A"), eine höhere durchschnittliche Abschlussnote (G3) haben als diejenigen, die in einer intakten Familie leben (Pstatus "T").

These 3 kann somit **"nicht bestätigt"** werden.

------------------------------------------------------------------------

**These 4**

"These 4: Es gibt einen Zusammenhang zwischen der Anzahl der vergangenen Fehlversuche und der Abschlussnote."

```{r}
correlation_failures_grade <- cor(student_data$failures, student_data$G3)
```

```{r}
ggplot(student_data, aes(x = failures, y = G3)) +
  geom_point() +
  geom_smooth(formula = y ~ x,method = "lm", se = FALSE, color = "red") +
  labs(title = "Zusammenhang zwischen Fehlversuchen und Abschlussnote", x = "Anzahl der Fehlversuche", y = "Abschlussnote")

```

Der Korrelationskoeffizient zeigt einen negativen Zusammenhang zwischen der Anzahl der Fehler und der Abschlussnote.
Dies bestätigt die These, dass mehr Fehler mit niedrigeren Noten verbunden sind.

Hier ist der Korrelationskoeffizient **-0.384297443081423**.

These 4 kann hiermit **"bestätigt"** werden.

------------------------------------------------------------------------

**These 6**

"These 6: Das Geschlecht hat einen Einfluss auf die Schulleistung."

```{r}
avg_grade_by_sex <- aggregate(G3 ~ sex, data = student_data_cleaned, FUN = mean)
print(avg_grade_by_sex)
```

```{r}
ggplot(student_data_cleaned, aes(x = sex, y = G3, fill = sex)) +
  geom_boxplot() +
  labs(title = "Einfluss des Geschlechts auf die Abschlussnote",
       x = "Geschlecht (M = männlich, F = weiblich)",
       y = "Abschlussnote (G3)")
```

Die Grafiken lassen erkennen, dass Männer im Schnitt die bessere Abschlussnote erreichen.
Dies würde die These 6 also **"bestätigen"**.

------------------------------------------------------------------------

**These 9**

"These 9: Es gibt einen Zusammenhang zwischen der Nutzung von Nachhilfe und den Abschlussnoten."

```{r}
avg_grade_by_paid <- aggregate(G3 ~ paid, data = student_data_cleaned, FUN = mean)
```

```{r}
ggplot(student_data_cleaned, aes(x = paid, y = G3, fill = paid)) +
  geom_boxplot() +
  labs(title = "Einfluss von Nachhilfe auf die Abschlussnote",
       x = "Nachhilfe (yes = ja, no = nein)",
       y = "Abschlussnote (G3)")
```

Diese Grafiken lassen etwas spannedes zur 9.
These erkennen: Studenten, welche Nachhilfe (paid) in Anspruch nehmen haben im Schnitt eine schlechtere Abschlussnote.
Dies ergibt Sinn, da Studenten, welche keine Nachhilfe benötigen generell eher besser durch den Stoff kommen.

These 9 kann also ebenfalls **"bestätigt"** werden.

## Ergebnis Thesenauswertung

| These   | Status          |
|---------|-----------------|
| These 1 | bestätigt       |
| These 2 | bestätigt\*     |
| These 3 | nicht bestätigt |
| These 4 | bestätigt       |
| These 5 | nicht bestätigt |
| These 6 | bestätigt       |
| These 7 | bestätigt       |
| These 8 | bestätigt       |
| These 9 | bestätigt       |

\* diese These wird mit der Exkludierung der nicht-gebildeten Elternteile bestätigt

# Machine Learning Modelle

## Datenaufteilung

Wir teilen den Datensatz "student_data_cleaned" in Trainings- und Testdaten auf:

```{r}
set.seed(123)
index <- createDataPartition(student_data_cleaned$G3, p = 0.8, list = FALSE)
train <- student_data_cleaned[index, ]
test <- student_data_cleaned[-index, ]

```

## Skalierung der Daten

Wir müssen ebenfalls eine Z-Standardisierung durchführen, um den Mittelwert auf 0 und die Standardabweichung auf 1 zu setzen.
Wir wählen erst Spalten aus die skaliert werden sollen und skalieren dann Trainings- und Testdaten der numerischen Werte:

```{r}
cols_to_scale <- train %>% select(where(is.numeric)) %>% colnames()
train_scale <- train %>%
  mutate(across(all_of(cols_to_scale), ~ scale(.) %>% as.vector))
test_scale <- test %>%
  mutate(across(all_of(cols_to_scale), ~ scale(.) %>% as.vector))
summary(train_scale)
```

## Training und Auswertung

Als Target der Modelle nutzen wir die Abschlussnote G3, diese hat (durch Thesen größtenteils bestätigt) die meisten Korrelationen und soll daher weiter vorhergesagt werden.

Als Features (Eingangsvariablen) nutzen wir folgende:

-   studytime

-   famrel

-   health

### Modell 1: Lineare Regression

Auf Basis der skalierten Daten wird nun ein lineares Regressionsmodell trainiert.

Danach können wir das Modell trainieren:

```{r}
linear_model <- lm(G3 ~ studytime + famrel + health, data = train_scale)
```

Wir fassen das Modell zusammen:

```{r}
summary(linear_model)
```

**Bewertung:**

studytime (Lernzeit): Ein positiver Koeffizient von 0.1672 bedeutet, dass mehr Lernzeit tendenziell zu besseren Abschlussnoten führt.
Dieser Effekt ist statistisch signifikant (p-Wert = 0.00102), was darauf hinweist, dass Lernzeit einen wichtigen Einfluss auf die Abschlussnote hat.

famrel (Beziehung zur Familie): Ein Koeffizient von 0.1027 bedeutet, dass eine bessere Beziehung zur Familie die Abschlussnote positiv beeinflusst.
Dieser Effekt ist ebenfalls statistisch signifikant (p-Wert = 0.04380).

health (Gesundheit): Der Koeffizient für Gesundheit ist -0.0307, was auf einen minimalen negativen Einfluss auf die Note hindeutet.
Allerdings ist dieser Effekt nicht signifikant (p-Wert = 0.54418), sodass keine klare Beziehung vom Einfluss der Gesundheit hergestellt werden kann.

Wir treffen jetzt Vorhersagen auf Basis des Modells:

```{r}
predictions_linear <- predict(linear_model, newdata = test_scale)
```

Dann erstellen wir den Mean Squared Error (MSE) für die Vorhersagen der Linearen Regression:

```{r}
mse_linear <- mean((predictions_linear - test_scale$G3)^2)
```

```{r}
print(paste("MSE für Lineare Regression:", mse_linear))
```

Der Mean Squared Error von knapp über **1** ist bei einer Punkteskala von G3 von 1-20 sehr akzeptabel und in Ordnung.

Wir werden es trotzdem erneut trainieren, um die Variablen Alter (age), Abwesenheiten (absences) und die Zeit mit Freunden (goout) mit hinzuzufügen.

**Erneutes Training**

```{r}
linear_model_new <- lm(G3 ~ studytime + famrel + health + age + absences + goout, data = train_scale)
predictions_linear_new <- predict(linear_model_new, newdata = test_scale)
mse_linear_new <- mean((predictions_linear_new - test_scale$G3)^2)
print(paste("MSE für Lineare Regression mit zusätzlichen Variablen:", mse_linear_new))
```

```{r}
v_actual <- test_scale$G3
v_predicted <- predictions_linear_new

# Berechnung der Residuen
v_residuals <- v_actual - v_predicted

# Histogramm der Residuen
hist(v_residuals, breaks = 10, col = "skyblue", 
     xlab = "Residuen (Fehler)", 
     main = "Verteilung der Vorhersagefehler (Residuen)",
     border = "white")
```

Zur Grafik: \n Das Modell scheint in den meisten Fällen relativ genau zu sein, da die meisten Fehler (Residuen) um 0 verteilt sind, was darauf hindeutet, dass die Vorhersagen oft nur geringfügig von den tatsächlichen Werten abweichen.
Die leichte negative Verzerrung (mehr Residuen im negativen Bereich) deutet darauf hin, dass das Modell bei einigen Studenten die Abschlussnoten etwas überschätzt hat.
Es gibt einige Ausreißer auf beiden Seiten (im Bereich von -2 bis -3 und +2 bis +3), die auf Studenten hinweisen, bei denen das Modell stark von der tatsächlichen Note abgewichen ist.

**Vergleich**

| Durchgang  | MSE      | Art                |
|------------|----------|--------------------|
| Modell 1.1 | 1.064507 | Lineare Regression |
| Modell 1.2 | 1.058334 | Lineare Regression |

Es wird durch den Vergleich also deutlich, dass die 3 neu eingebrachten Variablen im 2.
Durchgang der Linearen Regression keine wirkliche "Verbesserung" erbracht haben.
Das Modell ist mit ca.
5% Abweichung, gezeigt durch den MSE von ca.
\~1,05, relativ genau für das Target G3 mit einer Punkteverteilung von 1-20.

**Cross Validierung**

Wir führen eine 10-fache Cross Validierung auf den Trainingsdaten durch:

```{r}
set.seed(123)
cv_splits <- vfold_cv(train_scale, v = 10)
linear_spec <- linear_reg() %>%
  set_engine("lm")

cv_results_linear <- fit_resamples(
  linear_spec,
  G3 ~ studytime + famrel + health + age + absences + goout,
  resamples = cv_splits,
  metrics = metric_set(rmse, rsq)
)
```

Ergebnis:

```{r}
collect_metrics(cv_results_linear)
```

Der Vergleich folgt später.

### Modell 2: Entscheidungsbaum

Für ein weiteres Verfahren erstellen wir einen Entscheidungsbaum.
Durch die Gefahr des Overfittings, werden wir anschließend noch einen Random-Forest erstellen: Hier werden wir die gleichen Variablen wie in der Linearen Regression verwenden:

```{r}
decision_tree_model <- decision_tree(cost_complexity = 0.01, 
                                     tree_depth = 10, 
                                     min_n = 5) %>%
  set_engine("rpart") %>%
  set_mode("regression")

train_data_tree <- train_scale %>%
  select(G3, studytime, famrel, health, age, absences, goout)
```

Wir trainieren anschließend das Modell auf unsere Trainingsdaten und die Zielvariable G3 (Abschlussnote):

```{r}
tree_fit <- decision_tree_model %>%
  fit(G3 ~ studytime + famrel + health + age + absences + goout, 
      data = train_data_tree)
```

Dann erstellen wir auf Basis der Trainingsdaten erneut Vorhersagen und speichern diese:

```{r}
predictions_tree <- predict(tree_fit, new_data = test_scale) %>%
  pull(.pred)
```

**Mean Squared Error (MSE)**

```{r}
mse_tree <- mean((predictions_tree - test_scale$G3)^2)
print(paste("MSE für Entscheidungsbaum:", mse_tree))
```

Zur Visualisierung lassen wir uns den Entscheidungsbaum anzeigen:

```{r}
rpart.plot(tree_fit$fit, main = "Entscheidungsbaum für G3", roundint = FALSE)

```

In unserer Tabelle können wir also eine neue Zeile hinzufügen:

| Durchgang  | MSE      | Art                |
|------------|----------|--------------------|
| Modell 1.1 | 1.064507 | Lineare Regression |
| Modell 1.2 | 1.058334 | Lineare Regression |
| Modell 2   | 1.229209 | Entscheidungsbaum  |

Hieraus ist bereits ersichtlich, dass die Fehlerquote hier etwas höher ist, als noch bei der Linearen Regression

**Cross Validierung**

Wir führen ebenfalls beim Entscheidungsbaum die Cross Validierung durch:

```{r}
decision_tree_spec <- decision_tree(cost_complexity = 0.01, 
                                    tree_depth = 10, 
                                    min_n = 5) %>%
  set_engine("rpart") %>%
  set_mode("regression")
cv_results_tree <- fit_resamples(
  decision_tree_spec,
  G3 ~ studytime + famrel + health + age + absences + goout,
  resamples = cv_splits,
  metrics = metric_set(rmse, rsq)
)
```

```{r}
collect_metrics(cv_results_tree)

```

Der Vergleich folgt später.

### Modell 3: Random-Forest

Wir erstellen deshlab nun einen Random-Forest mit einer Anzahl von Bäumen = 1000:

```{r}
rand_forest_model <- rand_forest(mtry = sqrt(ncol(train_scale) - 1), 
                                 trees = 1000, 
                                 min_n = 5) %>% 
  set_engine("ranger") %>%  
  set_mode("regression")      
```

Außerdem werden die gleichen Features verwendet, wie in der Linearen Regression und dem Entscheidungsbaum.
Anschließend trainieren wir das Modell erneut auf unsere Trainingsdaten und die Zielvariable G3 (Abschlussnote):

```{r}
train_data_forest <- train_scale %>%
  select(G3, studytime, famrel, health, age, absences, goout)
rf_fit <- rand_forest_model %>%
  fit(G3 ~ studytime + famrel + health + age + absences + goout, 
      data = train_data_forest)
```

Dann erstellen wir auf Basis der Trainingsdaten erneut Vorhersagen und speichern diese:

```{r}
predictions_rf <- predict(rf_fit, new_data = test_scale) %>%
  pull(.pred)
```

**Mean Squared Error (MSE)**

```{r}
mse_rf <- mean((predictions_rf - test_scale$G3)^2)
print(paste("MSE für Random Forest:", mse_rf))
```

**Feauture Wichtigkeit im Random Forest** Für eine genauere Interpretation fertigen wir noch einen Random Forest zur Wichtigkeit der betroffenen Variablen an:

```{r}
rf_model_ranger <- ranger(G3 ~ studytime + famrel + health + age + absences + goout, 
                          data = train_scale, 
                          importance = "impurity",
                          num.trees = 1000)
importance_rf <- rf_model_ranger$variable.importance
importance_percent <- importance_rf / sum(importance_rf) * 100
importance_df <- data.frame(Feature = names(importance_percent), Importance = importance_percent)
```

Außerdem lassen wir uns die Wichtigkeit anzeigen:

```{r}
ggplot(importance_df, aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_col(fill = "skyblue") +
  ggtitle("Feature-Wichtigkeit im Random Forest (ranger)") +
  xlab("Feature") + 
  ylab("Wichtigkeit") +
  theme_minimal()
```

Absences hat in unserem Random Forest den höchsten Einfluss auf die Abschlussnote.

**Cross Validierung** Und auch beim Random Forest führen wir eine Cross Validierung durch:

```{r}
rf_spec <- rand_forest(mtry = sqrt(ncol(train_scale) - 1), trees = 1000, min_n = 5) %>%
  set_engine("ranger") %>%
  set_mode("regression")
cv_results_rf <- fit_resamples(
  rf_spec,
  G3 ~ studytime + famrel + health + age + absences + goout,
  resamples = cv_splits,
  metrics = metric_set(rmse, rsq)
)
```

```{r}
collect_metrics(cv_results_rf)
```

### Leistungsbewertung der Modelle und Vergleich

Wir haben für den Mean Squared Error folgende Tabelle:

| Durchgang  | MSE      | Art                |
|------------|----------|--------------------|
| Modell 1.1 | 1.064507 | Lineare Regression |
| Modell 1.2 | 1.058334 | Lineare Regression |
| Modell 2   | 1.229209 | Entscheidungsbaum  |
| Modell 3   | 0.988686 | Random Forest      |

Alle Modelle bewegen sich um 1 Notenpunkt Abweichung, dies ist sehr gut.
Es wird jedoch auch klar, dass der Random Forest gegenüber dem Entscheidungsbaum eine höhere Genauigkeit vorweist.
Dies liegt mitunter an der 1000x Durchführung.

**Vergleich der Cross Validierung** 

| Modell | RMSE | R² | RMSE-Standardabweichung | R²-Standardabweichung | 
|---------------------|---------------|---------------|-------------------------|-----------------------| 
| Lineare Regression | 0.9743 | 0.0813 | 0.0345 | 0.0244 | 
| Entscheidungsbaum | 1.0256 | 0.0514 | 0.0306 | 0.0162 |
| Random Forest | 0.9473 | 0.1233 | 0.0273 | 0.0249 |

Der Vergleich zeigt uns, dass der Random Forest insgesamt das beste Modell ist, da es den niedrigsten MSE/RMSE und das höchste R² aufweist.
Das bedeutet, dass der Random Forest im Vergleich zu den anderen Modellen die genauesten Vorhersagen trifft und die Varianz in den Abschlussnoten besser erklärt.

Der Entscheidungsbaum schneidet am schlechtesten ab, sowohl in Bezug auf MSE/RMSE als auch R².

# Kritische Bewertung und Fazit

Aufgrund des Umfanges der Arbeit bietet es sich an in einer nächsten Analyse weitere Features zu nutzen, um die Aussagekraft der Vorhersagen zu erhöhen.
Ebenfalls könnte die Durchführung eines Hyperparametertunings (vgl. Housing, Gorniak, 2023) unter z.B.
<https://tune.tidymodels.org/reference/tune_grid.html> mit Hilfe eines Grid Search für bessere Ergebnisse sorgen.

Dennoch bietet diese Analyse einen fundierten Einblick in die Vorhersage der Abschlussnoten der Studenten anhand mehrerer Features, ebenfalls konnte ein Großteil der aufgestellten Thesen durch die explorative Datenanalyse bestätigt werden.

In Zukunft kann jedoch die Basis der Daten erweitert werden, sodass Vorhersagen noch besser, noch präziser und genauer getroffen werden können.

# Quellen

Zur Bearbeitung und Formatierung der Arbeit wurde das [offizielle Quarto-Wiki](https://quarto.org/docs/authoring/markdown-basics.html) genutzt, um Grafiken anschaulicher zu gestalten oder bestimmte Punkte besonders hervorzuheben.

Die Quelle der Daten ist, wie in der Einleitung beschrieben, ein bei [kaggle.com](https://www.kaggle.com/datasets/uciml/student-alcohol-consumption/data) zur Verfügung gestellter Datensatz bestehend aus 2 (bzw. 3) .csv Dateien.

Bei der Struktur wurde sich, wie von der Dozentin vorgeschlagen, am Analysebeispiel "Housing" von Frau Prof. Dr. Gorniak (2023) orientiert.

# Weiteres

Dieses Projekt wird zu Bildungszwecken in einem Github Repository bereitgestellt um Quarto, sowie R demonstrieren zu können.
Ebenfalls sollen so weitere Analysen ermöglicht werden bzw.
die Arbeit dieses Dokumentes fortgesetzt werden.
